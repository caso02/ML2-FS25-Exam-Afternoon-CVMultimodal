{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4cf56921",
      "metadata": {
        "id": "4cf56921"
      },
      "source": [
        "# Exam Machine Learning 2: Computer Vision & Multimodal Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f7fb22f",
      "metadata": {
        "id": "0f7fb22f"
      },
      "source": [
        "## Personal information (please complete)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06c19c6f",
      "metadata": {},
      "source": [
        "<table>\n",
        "  <tr>\n",
        "    <td>Name:</td>\n",
        "    <td></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Surname:</td>\n",
        "    <td></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Student ID Number:</td>\n",
        "    <td></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Modul:</td>\n",
        "    <td>Machine Learning 2</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Exam date / Room / Time:</td>\n",
        "    <td>20.5.2025 / Raum: SM O1.01 / 18:15 – 19:45</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Allowed materials:</td>\n",
        "    <td>w.3ML2-WIN.GK (Machine Learning II)<br>Open Book, Open Internet, Personal Computer</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "  <td>Not allowed:</td>\n",
        "  <td>The use of any form of generative AI (e.g., Copilot, ChatGPT) to assist in solving the exercise is not permitted. <br> However, using such tools as part of the exercise itself (e.g., making API calls to them if required by the task) is allowed. <br> Any form of communication or collaboration with other people is not permitted</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61847f62",
      "metadata": {
        "id": "61847f62"
      },
      "source": [
        "## Evaluation criteria\n",
        "\n",
        "The code for each task is evaluated according to the following scheme. The total score is a maximum of 48 points, with each task earning up to 8 or 4 points respectively.\n",
        "\n",
        "\n",
        "| **Category**                         | **Description**                                                                                                                                               | **Points Distribution**                 |\n",
        "|-------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------|\n",
        "| **Code not executable or results not relevant** | The code does not run or does not meet the requirements of the aspect (e.g., images are not loaded, text output from extraction is missing, bounding boxes are not displayed). | **0 points**                            |\n",
        "| **Code executable, but with major flaws**         | The code runs, but key parts of the functionality for an aspect are missing (e.g., incomplete extraction of image information or errors in schema definition). | **25% of the maximum achievable points** |\n",
        "| **Code executable, but with moderate flaws**      | The code runs and provides partially correct results for an aspect, but important details are missing (e.g., inaccurate bounding boxes, incomplete integration of extracted data). | **50% of the maximum achievable points** |\n",
        "| **Code executable, but with minor flaws**         | The code largely meets the requirements of an aspect, but there are minor errors or deviations (e.g., extraction not robust, slight schema mismatches, prompt not clearly formulated → partially unstable output). | **75% of the maximum achievable points** |\n",
        "| **Code executable and correct**                  | The code fully meets the requirements of the aspect and delivers the expected results without errors (e.g., correct extraction, complete bounding boxes, clean integration). | **100% of the maximum achievable points** |\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a8b7408",
      "metadata": {
        "id": "8a8b7408"
      },
      "source": [
        "## **Preparation**\n",
        "\n",
        "1.) pip install the needed packages (see cell under). \n",
        "\n",
        "2.) Load your API keys in a new .env file in the temporary Colab Space or GitHub Codespace, as well as drag and drop the provided images for the exam (for Codespace not needed: they are in the repository)\n",
        "\n",
        "IMPORTANTE NOTE: Be aware that to import specific packages later in the code (depending on how you decide to solve the exercise and where you are running it), might require installing the relative library before. Therefore you might need more \"!pip install...\" cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VPWQBtzjuidD",
      "metadata": {
        "id": "VPWQBtzjuidD"
      },
      "outputs": [],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df6acba0",
      "metadata": {
        "id": "df6acba0"
      },
      "source": [
        "## **Task**\n",
        "\n",
        "### **Task Description**\n",
        "\n",
        "As part of this assignment, you are asked to perform object detection, with a model of your choice which uses textual information to identify relevant elements in images.\n",
        "\n",
        "**Context:**\n",
        "In this scenario, a staff member (e.g., a human nurse or triage assistant) is conducting initial patient intake at a clinic. As part of this process, the staff member interviews each arriving patient and takes handwritten notes, including details such as personalia, symptoms, background information, required diagnostics or tests. These notes are recorded on a medical_note.png file.\n",
        "\n",
        "After the triage process, the patients move to a waiting area, shown in **`hospital_waiting_room.png`**, where multiple people are present, including patients, visitors, and medical staff.\n",
        "\n",
        "You are developing a program for a hypothetical reception steward robot. This robot is responsible for reading the triage notes and correctly identifying the patient in the waiting room who matches the description and the next location where the patient needs to be brought (e.g. radiology, lab, doctor examiantion room).\n",
        "The first patient you need to identify is the one described in **`medical_note1.png`**.\n",
        "\n",
        "**Objective:**\n",
        "\n",
        "\n",
        "Analyze the information in **`medical_note1.png`** and extract them in a structured form, based on a predefined extraction schema.\n",
        "Identify the correct individual in **`hospital_waiting_room.png`** based on the relevant attributes extracted from the medical note.\n",
        "Identify the room where the person needs to be brought based on the relevant attributes extracted from the medical note.\n",
        "Draw a bounding box around the identified person and identified room and save the resulting image as **`hospital_waiting_room_person1identified.jpeg`**.\n",
        "\n",
        "To test generalizability, repeat the process using a second patient, contained in **`medical_note2.png`**:\n",
        "\n",
        "Use **`medical_note2.png`**, and save the output image as **`hospital_wiaiting_room_patient2_identified.png`**.\n",
        "\n",
        "Note:\n",
        "You may use any model of your choice. Focus on how to extract structured or relevant information from the textual note and effectively match it to the visual content of the image.\n",
        "\n",
        "\n",
        "\n",
        "**Results to be Uploaded (Moodle)**  \n",
        "  The following documents must be uploaded at the end of this task in the dedicated section in Moodle:  \n",
        "  - The Notebook file you used (this file) with all the code provided by you to solve the task.  \n",
        "  - The obtained image **`hospital_waiting_room_person1identified`**.  \n",
        "  - the obtained image **`hospital_waiting_room_person2identified`**.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b8df3dd",
      "metadata": {
        "id": "9b8df3dd"
      },
      "source": [
        "## Utils (Helper Functions):\n",
        "\n",
        "Here you will find some pre-made functions to help you visualize and plot bounding boxes, as well as parse different types of output. You can use these or create new functions yourself if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2232367a",
      "metadata": {
        "id": "2232367a"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from PIL import Image, ImageDraw\n",
        "from PIL import ImageColor\n",
        "from dotenv import load_dotenv\n",
        "import re\n",
        "import os\n",
        "\n",
        "additional_colors = [colorname for (colorname, colorcode) in ImageColor.colormap.items()]\n",
        "\n",
        "def plot_bounding_boxes(im, noun_phrases_and_positions):\n",
        "    \"\"\"\n",
        "    Plots bounding boxes on an image with markers for each noun phrase, using PIL, normalized coordinates, and different colors.\n",
        "\n",
        "    Args:\n",
        "        img_path: The path to the image file.\n",
        "        noun_phrases_and_positions: A list of tuples containing the noun phrases\n",
        "         and their positions in normalized [y1 x1 y2 x2] format.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the image\n",
        "    img = im\n",
        "    width, height = img.size\n",
        "    print(img.size)\n",
        "    # Create a drawing object\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    # Define a list of colors\n",
        "    colors = [\n",
        "    'red',\n",
        "    'green',\n",
        "    'blue',\n",
        "    ] + additional_colors\n",
        "\n",
        "    # Iterate over the noun phrases and their positions\n",
        "    for i, (noun_phrase, (y1, x1, y2, x2)) in enumerate(\n",
        "        noun_phrases_and_positions):\n",
        "        # Select a color from the list\n",
        "        color = colors[i % len(colors)]\n",
        "\n",
        "        # Convert normalized coordinates to absolute coordinates\n",
        "        abs_x1 = int(x1/1000 * width)\n",
        "        abs_y1 = int(y1/1000 * height)\n",
        "        abs_x2 = int(x2/1000 * width)\n",
        "        abs_y2 = int(y2/1000 * height)\n",
        "\n",
        "        # Draw the bounding box\n",
        "        draw.rectangle(\n",
        "            ((abs_x1, abs_y1), (abs_x2, abs_y2)), outline=color, width=4\n",
        "        )\n",
        "\n",
        "        # Draw the text\n",
        "        draw.text((abs_x1 + 8, abs_y1 + 6), noun_phrase, fill=color)\n",
        "\n",
        "    # Display the image\n",
        "    img.show()\n",
        "\n",
        "# @title Parsing utils\n",
        "def parse_list_boxes(text):\n",
        "  result = []\n",
        "  for line in text.strip().splitlines():\n",
        "    # Extract the numbers from the line, remove brackets and split by comma\n",
        "    try:\n",
        "      numbers = line.split('[')[1].split(']')[0].split(',')\n",
        "    except:\n",
        "      numbers =  line.split('- ')[1].split(',')\n",
        "\n",
        "    # Convert the numbers to integers and append to the result\n",
        "    result.append([int(num.strip()) for num in numbers])\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "def parse_list_boxes_with_label(text):\n",
        "  text = text.split(\"```\\n\")[0]\n",
        "  return json.loads(text.strip(\"```\").strip(\"python\").strip(\"json\").replace(\"'\", '\"').replace('\\n', '').replace(',}', '}'))\n",
        "\n",
        "\n",
        "\n",
        "def parse_json_in_output(output):\n",
        "    \"\"\"\n",
        "    Extracts and converts JSON-like data from the given text output to a Python dictionary.\n",
        "\n",
        "    Args:\n",
        "        output (str): The text output containing the JSON data.\n",
        "\n",
        "    Returns:\n",
        "        dict: The parsed JSON data as a Python dictionary.\n",
        "    \"\"\"\n",
        "    # Regex to extract JSON-like portion\n",
        "    json_match = re.search(r\"\\{.*?\\}\", output, re.DOTALL)\n",
        "    if json_match:\n",
        "        json_str = json_match.group(0)\n",
        "\n",
        "\n",
        "        # Fix single quotes and ensure proper JSON formatting\n",
        "        json_str = json_str.replace(\"'\", '\"')  # Replace single quotes with double quotes\n",
        "        print(json_str)\n",
        "        try:\n",
        "            # Convert the fixed JSON string into a dictionary\n",
        "            json_data = json.loads(json_str)\n",
        "            return json_data\n",
        "        except json.JSONDecodeError:\n",
        "            return \"The extracted JSON is still not valid after formatting.\"\n",
        "    else:\n",
        "        return \"No JSON data found in the given output.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c2af9ac",
      "metadata": {
        "id": "4c2af9ac"
      },
      "source": [
        "### <b>Task (1): Loading and Visualizing Images / Importing Necessary Libraries</b>\n",
        "Details of the task:\n",
        "\n",
        "Load and visualize the images medical_note1.png and hospital_waiting_room.png.\n",
        "Import the necessary libraries for this assignment here.\n",
        "\n",
        "<b style=\"color: gray;\">(maximum achievable points: 4)</b>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1033774",
      "metadata": {
        "id": "f1033774"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cee9ae2",
      "metadata": {
        "id": "6cee9ae2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c12bb41e",
      "metadata": {
        "id": "c12bb41e"
      },
      "source": [
        "### <b>Task (2): Definition of a Structured Schema for Information Extraction</b>\n",
        "Details of the task:\n",
        "\n",
        "Define a structured schema (e.g., a JSON schema) to organize the information extracted from the image medical_note1.png. The schema should clearly define the fields and structure required to represent the extracted data.\n",
        "Pay attention to how the parsing function is defined – you might need to modify it if nested elements are present in your schema.\n",
        "\n",
        "<b style=\"color: gray;\">(maximum achievable points: 8)</b>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dcd95f3",
      "metadata": {
        "id": "2dcd95f3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "79185d5d",
      "metadata": {
        "id": "79185d5d"
      },
      "source": [
        "### <b>Task (3): Extraction of Visual Information via Prompting</b>\n",
        "Details of the task:\n",
        "\n",
        "Extract structured visual information from the image medical_note1.png using textual prompting to obtain the data needed for patient identification. This should follow the previously defined schema.\n",
        "\n",
        "Note: Depending on the model you choose, the syntax for input and output using structured schemas may vary. Consult the model specifications on this topic and refer to them accordingly.\n",
        "\n",
        "<b style=\"color: gray;\">(maximum achievable points: 8)</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a6e4a3c",
      "metadata": {
        "id": "6a6e4a3c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2916c9a4",
      "metadata": {
        "id": "2916c9a4"
      },
      "source": [
        "### <b>Task (4): Processing the Textual Output of Visual Extraction</b>\n",
        "Details of the task:\n",
        "\n",
        "Extract and parse the JSON output from the visual extraction into a suitable data structure.\n",
        "To double-check, specifically access and print the first key and corresponding value of the extracted data structure.\n",
        "\n",
        "Note: There is a helper function available in the utils that you can use.\n",
        "\n",
        "<b style=\"color: gray;\">(maximum achievable points: 4)</b>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3f1c7da",
      "metadata": {
        "id": "e3f1c7da"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "572fffcd",
      "metadata": {
        "id": "572fffcd"
      },
      "source": [
        "### <b>Task (5): Integration of Extracted Data into a New Prompt for Further Identification</b>\n",
        "Details of the task:\n",
        "\n",
        "Use the information (or parts of it) obtained from the previous output to create a prompt needed to identify the correspondent person in hospital_waiting_room.png. Automatically integrate this information using the data structure created in the previous cells. Then, identify the patient and output the coordinates indicating his/her position in the image.\n",
        "\n",
        "<b style=\"color: gray;\">(maximum achievable points: 8)</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37af78a2",
      "metadata": {
        "id": "37af78a2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "94418a6b",
      "metadata": {
        "id": "94418a6b"
      },
      "source": [
        "### <b>Task (6): Visualization of Bounding Boxes</b>\n",
        "Details of the task:\n",
        "\n",
        "Plot the bounding boxes on the image hospital_waitiing_room.png and check whether the detection appears plausible. Save the resulting image as hospital_waiting_room_patient1identified.png\n",
        ".\n",
        "Note: There are helper functions available in the utils that you can use.\n",
        "\n",
        "<b style=\"color: gray;\">(maximum achievable points: 8)</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f22926",
      "metadata": {
        "id": "64f22926"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74fe7958",
      "metadata": {
        "id": "74fe7958"
      },
      "source": [
        "### <b>Task (7): Pipeline Validation</b>\n",
        "Details of the task:\n",
        "\n",
        "Test your complete code pipeline with a new image (medical_note2.png). Apply exactly the same code used so far and check whether it works with this new prescription for another patient.\n",
        "Adjust the prompts if necessary to improve robustness (generalizability).\n",
        "\n",
        "However, do not change the existing cells—instead, copy your previous code here and modify it as a new version so that the changes (delta) remain visible.\n",
        "Save the resulting image as hospital_waiting_room_patient2identified.png.\n",
        "\n",
        "<b style=\"color: gray;\">(maximum achievable points: 4)</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba49c882",
      "metadata": {
        "id": "ba49c882"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8bkLJUJxC-I4",
      "metadata": {
        "id": "8bkLJUJxC-I4"
      },
      "source": [
        "### <b>Task (8): Ethical Assessment</b>\n",
        "Details of the task:\n",
        "\n",
        "Evaluate which type of risk is associated with such an AI system according to the EU AI Act? Use the specific category incldued in the legislation .\n",
        "\n",
        "Provide a justification for your answer and legal requirement for a potential deployment of such a system (if allowed).\n",
        "\n",
        "<b style=\"color: gray;\">(maximum achievable points: 4)</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5HDidL0hEpHd",
      "metadata": {
        "id": "5HDidL0hEpHd"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "61105e3d",
      "metadata": {
        "id": "61105e3d"
      },
      "source": [
        "### Jupyter notebook --footer info-- (please always provide this at the end of each notebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04fb889e",
      "metadata": {
        "id": "04fb889e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import platform\n",
        "import socket\n",
        "from platform import python_version\n",
        "from datetime import datetime\n",
        "\n",
        "print('-----------------------------------')\n",
        "print(os.name.upper())\n",
        "print(platform.system(), '|', platform.release())\n",
        "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "print('Python Version:', python_version())\n",
        "print('IP Address:', socket.gethostbyname(socket.gethostname()))\n",
        "print('-----------------------------------')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dsenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
